{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries needed for the exercise (numpy, matplotlib, and torch)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset (Only necessary for colab)\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "if not os.path.exists('decoy-mnist.npz'):\n",
    "    urlretrieve('https://github.com/SIDN-IAP/intro-lab/blob/master/decoy-mnist.npz?raw=true', 'decoy-mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoy MNIST Lab\n",
    "\n",
    "In this lab, we'll introduce some basic concepts in interpretable machine learning through a short series of exerises on the \"Decoy MNIST\" dataset from [this paper](https://arxiv.org/pdf/1703.03717.pdf).\n",
    "\n",
    "## Load and visualize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Decoy MNIST dataset\n",
    "cached = np.load('./decoy-mnist.npz')\n",
    "arrays = [cached[f] for f in sorted(cached.files)]\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = arrays\n",
    "\n",
    "# Verify we get 50000/10000/10000 x 784\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoy MNIST is a version of the [MNIST handwritten digit dataset](http://yann.lecun.com/exdb/mnist/) that has been modified to include a special color swatch in a random corner of the image. In the training (n=50000) and validation (n=10000) sets, the shade of this color swatch corresponds exactly to the digit label, while in the test set, the shade is chosen randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some examples from the training / validation / test sets:\n",
    "\n",
    "def random_digits_matching(digit, X, y):\n",
    "    idx = np.argwhere(y == digit)[:,0]\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx]\n",
    "  \n",
    "def plot_digit(x):\n",
    "    \"\"\"Plot 2D image in black and white.\"\"\"\n",
    "    lim = np.abs(x).max()\n",
    "    plt.imshow(x.reshape(-28,28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "for split, X, y in [('Train', X_train, y_train), ('Validation', X_val, y_val), ('Test', X_test, y_test)]:\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    fig.suptitle(split + \" Set Images\", fontsize=16)\n",
    "    plot = 0\n",
    "    for digit in [1, 3, 6]:\n",
    "        images = random_digits_matching(digit, X, y)\n",
    "        for i in range(3):\n",
    "            plot += 1\n",
    "            plt.subplot(3,3,plot)\n",
    "            plot_digit(images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding this color swatch, we've deliberately introduced what can either be seen as a _redundancy_ (in that we have two conceptually independent ways of predicting the label during training) or an _incompleteness_ (in that the training images and labels now actually provide us **less** information about the right function to learn).\n",
    "\n",
    "We'll explore the consequences of this redundancy / incompleteness below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network class\n",
    "\n",
    "To test out how models react to redundancy, we first need to define at least one type of model. For this lab, we'll focus on a relatively simple 784x50x50x10 fully-connected neural network (to minimize training time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    \"\"\"Convert Nx1 flat list of digits to Nx10 'one-hot' encoded array.\"\"\"\n",
    "    values = np.arange(10)\n",
    "    return np.array([values == v for v in y]).astype(int)\n",
    "  \n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a 2-hidden-layer fully connected neural network w/ ReLU activations.\"\"\"\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 50) \n",
    "        self.fc2 = nn.Linear(50, 50)  \n",
    "        self.fc3 = nn.Linear(50, 10)  \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the neural network, mapping input tensors -> unnormalized digit logits.\"\"\"\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "      \n",
    "    def predict(self, x):\n",
    "        \"\"\"Map numpy input images to digit predictions\"\"\"\n",
    "        images = torch.Tensor(x)\n",
    "        logits = self(images)\n",
    "        return np.argmax(logits.data.numpy(), axis=1)\n",
    "      \n",
    "    def accuracy(self, x, y):\n",
    "        \"\"\"Compute accuracy of predictions.\"\"\"\n",
    "        return (self.predict(x) == y).mean()\n",
    "      \n",
    "    def input_grads(self, x):\n",
    "        \"\"\"Map numpy input images to saliency maps (as log-probability input gradients)\"\"\"\n",
    "        images = Variable(torch.Tensor(x), requires_grad=True)\n",
    "        logits = self(images) # pass images through the network\n",
    "        logprobs = -F.log_softmax(logits, 1) # compute log-probs for each digit\n",
    "        logprobs.sum().backward() # sum log-probs to get a scalar quantity dependent on all outputs\n",
    "        return images.grad.data.numpy() # return the input gradient\n",
    "      \n",
    "    def fit(self, X, y, lr=0.001, weight_decay=0.01, epochs=None, batch_size=256):\n",
    "        \"\"\"Fit the neural network on inputs `X` and labels `y`\n",
    "        for `epochs` passes through the dataset in `batch_size` increments\n",
    "        with `lr` learning rate and the provided L2 `weight_decay`.\"\"\"\n",
    "        \n",
    "        # Train for about 2000 steps, by default\n",
    "        if epochs is None:\n",
    "          epochs = (2000 * batch_size) // len(X)\n",
    "          \n",
    "        # Use cross-entropy + weight decay loss and Adam\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Convert numpy dataset to tensors\n",
    "        dataset = data.TensorDataset(torch.Tensor(X), torch.Tensor(one_hot(y)))\n",
    "        loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Main training loop\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(Variable(images))\n",
    "                loss = loss_func(outputs, Variable(labels))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print('Epoch {}, Loss: {:.4f}'.format(epoch+1, loss.data))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network on training data\n",
    "\n",
    "Let's fit our model on the data (using a relatively high weight decay):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNeuralNetwork()\n",
    "net.fit(X_train, y_train, lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine validation and test accuracy\n",
    "\n",
    "Now that we've fit our model, we can look at its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation accuracy:\", net.accuracy(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy:\", net.accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that test accuracy, while still well above random guessing, is significantly lower than validation accuracy.\n",
    "\n",
    "This is likely because the testing dataset contains two conflicting rules: the digit image and the color swatch. The fact that test accuracy is (likely) closer to 1 than 1/10 suggests the model is more reliant on the digit image than the color swatch, but it's still clearly confused.\n",
    "\n",
    "Let's try to investigate what's going on using a saliency method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute input gradients, a basic saliency method\n",
    "# (we'll cover this in the next section in more detail)\n",
    "grads = net.input_grads(X_test)\n",
    "\n",
    "# Plot them as heatmaps \n",
    "def plot_grad(x):\n",
    "    \"\"\"Plot gradient as heatmap, where red = positive, blue = negative, and white = 0.\"\"\"\n",
    "    lim = np.abs(x).max()\n",
    "    plt.imshow(x.reshape(-28,28), cmap='bwr', vmin=-lim, vmax=lim)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for i in range(10):\n",
    "  plt.subplot(2,10,i+1)\n",
    "  plot_digit(X_test[i])\n",
    "for i in range(10):\n",
    "  plt.subplot(2,10,i+11)\n",
    "  plot_grad(grads[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots highlight areas where the model is locally sensitive to small changes (fuller explanation below).\n",
    "\n",
    "**The main takeaway here is that the model's outputs are very sensitive both to changes in the corner pixels and to changes in the main digit region, suggesting a reasonable dependence on both.**\n",
    "\n",
    "<small>\n",
    "If you're curious about how to understand _exactly_ what these plots mean, you're not the only one -- saliency maps are notorious for being difficult to interpret, and we'll cover these issues in later classes. However, for completeness, here's what these plots literally mean:\n",
    "- whitening the image at red areas increases the model's confidence in its prediction\n",
    "- whitening the image at blue areas decreases the model's confidence in its prediction\n",
    "- the degree of redness or blueness quantifies the magnitude of this increase or decrease\n",
    "</small>\n",
    " \n",
    "\n",
    "# Exercises for you\n",
    "\n",
    "## Exercise 1: Create a second neural network, except this time, `fit` it on `X_test` / `y_test` and then evaluate its performance / visualize its gradients on the training or validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see any difference in behavior between this new model and the net you fit on the original training set, either in its accuracy statistics or its saliency maps? What to these quantitative values (accuracy + gradients) tell you about its qualitative differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Explore the effect of weight decay at `0.0`, `0.001`, `0.01`, `0.1`, and `1.0`\n",
    "\n",
    "In our `fit` method, we pass in `weight_decay` value of `0.01`. This means that during training, we're minimizing not just the cross-entropy loss (i.e. prediction error), but also the complexity of our model --- as quantifiied by `0.01` times the sum of the squares of its weights.\n",
    "\n",
    "In this example, we'd like you to test out the effect of the weight decay on the model's sensitivity to the color swatch and on its saliency maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decays = [0.0, 0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for each weight decay value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of their validation and test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each model's input gradients for the first 10 test examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the different models? Does the gap between validation and test accuracy change as a function of weight decay? Does the validation accuracy of the model change? How about the smoothness of the saliency maps?  What, if anything, do you feel you can _interpret_ about the differences between each of the models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
